{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import psutil\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "sys.path.insert(0, '/home/users/brezovec/.local/lib/python3.6/site-packages/lib/python/')\n",
    "import ants\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_ch2 = '/oak/stanford/groups/trc/data/Ashley2/imports/20210802/fly1_40s-011/ch2_stitched.nii'\n",
    "file_ch1 = '/oak/stanford/groups/trc/data/Ashley2/imports/20210802/fly1_40s-011/ch1_stitched.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch2_img = nib.load(file_ch2) # this loads a proxy\n",
    "ch1_img = nib.load(file_ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 236, 29, 6993)\n"
     ]
    }
   ],
   "source": [
    "dims = ch2_img.header.get_data_shape()\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder there\n"
     ]
    }
   ],
   "source": [
    "## first make an h5py file\n",
    "save_path = '/oak/stanford/groups/trc/data/Ashley2/imports/20210802/fly1_40s-011/test/'\n",
    "if os.path.exists(save_path):\n",
    "    print('folder there')\n",
    "else:\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "save_file_ch1 = os.path.join(save_path, 'test_MOCO_ch1.h5')\n",
    "save_file_ch2 = os.path.join(save_path, 'test_MOCO_ch2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created empty hdf5 file ch1\n",
      "created empty hdf5 file ch2\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(save_file_ch1, 'w') as f_ch1:\n",
    "    dset_ch1 = f_ch1.create_dataset('data', (*dims[:3],0), maxshape=(*dims[:3],None), dtype='float32')\n",
    "print('created empty hdf5 file ch1')\n",
    "\n",
    "with h5py.File(save_file_ch2, 'w') as f_ch2:\n",
    "    dset_ch2 = f_ch2.create_dataset('data', (*dims[:3],0), maxshape=(*dims[:3],None), dtype='float32')\n",
    "    zscore_ch2 = f_ch2.create_dataset('zscore', (*dims[:3],0), maxshape=(*dims[:3],None), dtype='float32')\n",
    "print('created empty hdf5 file ch2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate meanbrain\n",
    "small_brain_size = 3  #use for testing\n",
    "meanbrain = np.zeros(dims[:3])\n",
    "\n",
    "#for i in range(dims[-1]):\n",
    "for i in range(small_brain_size):\n",
    "    meanbrain += ch1_img.dataobj[...,i]\n",
    "meanbrain = meanbrain/small_brain_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make fixed moco\n",
    "fixed = ants.from_numpy(np.asarray(meanbrain, dtype='float32'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop over vols to get moco (use small_brain_size for test)\n",
    "\n",
    "for i in range(small_brain_size):\n",
    "    vol = ch1_img.dataobj[...,i]\n",
    "    \n",
    "    moving = ants.from_numpy(np.asarray(vol, dtype='float32'))\n",
    "    \n",
    "    # Motion correct\n",
    "    moco = ants.registration(fixed,moving,type_of_transform='SyN')\n",
    "    moco_out = moco['warpedmovout'].numpy()\n",
    "    transformlist = moco['fwdtransforms']\n",
    "\n",
    "    ##also make ch2 warped brain correction using transforms\n",
    "    #if ch2_brain_file is not None: \n",
    "    ch2_img = nib.load(file_ch2) # this loads a proxy\n",
    "    ch2_vol = ch2_img.dataobj[...,i]\n",
    "    ch2_moving = ants.from_numpy(np.asarray(ch2_vol, dtype='float32'))\n",
    "    #moco_ch2 = ants.apply_transforms(meanbrain, ants.from_numpy(ch2_moving), transformlist).numpy()\n",
    "    #moco_ch2 = ants.apply_transforms(meanbrain, ch2_moving, transformlist).numpy()\n",
    "    moco_ch2 = ants.apply_transforms(meanbrain, ch2_moving, transformlist)\n",
    "    #moco_ch2 = moco_ch2.numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### DELETE INVERSE TRANSFORMS\n",
    "    transformlist = moco['invtransforms']\n",
    "    for x in transformlist:\n",
    "        if '.mat' not in x:\n",
    "            os.remove(x)\n",
    "            \n",
    "    ### DELETE FORWARD TRANSFORMS\n",
    "    transformlist = moco['fwdtransforms']\n",
    "    for x in transformlist:\n",
    "        if '.mat' not in x:\n",
    "            os.remove(x)\n",
    "            \n",
    "\n",
    "    # Append to hdf5 file\n",
    "    with h5py.File(save_file_ch1, 'a') as f_ch1:\n",
    "\n",
    "        # Increase hdf5 size by one brain volume\n",
    "        current_num_vol = f_ch1['data'].shape[-1] # this is the last axis, which is time\n",
    "        new_num_vol = current_num_vol + 1 # will want one more volume\n",
    "        f_ch1['data'].resize(new_num_vol,axis=3) # increase size by one volume\n",
    "\n",
    "        # Append to hdf5 file\n",
    "        f_ch1['data'][...,-1] = moco_out  ##\n",
    "        \n",
    "    # Append to hdf5 file\n",
    "    with h5py.File(save_file_ch2, 'a') as f_ch2:\n",
    "\n",
    "        # Increase hdf5 size by one brain volume\n",
    "        current_num_vol = f_ch2['data'].shape[-1] # this is the last axis, which is time\n",
    "        new_num_vol = current_num_vol + 1 # will want one more volume\n",
    "        f_ch2['data'].resize(new_num_vol,axis=3) # increase size by one volume\n",
    "\n",
    "        # Append to hdf5 file\n",
    "        f_ch2['data'][...,-1] = moco_ch2  ##\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 1.17GB\n"
     ]
    }
   ],
   "source": [
    "memory_usage = psutil.Process(os.getpid()).memory_info().rss*10**-9\n",
    "print('Current memory usage: {:.2f}GB'.format(memory_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##zscore section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 236, 29, 10)\n",
      "<Closed HDF5 dataset>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# open h5py\n",
    "\n",
    "#I am not sure how much memory this will take and if it loads a proxy or if it actually puts the whole thing in memory\n",
    "#if it puts the whole thing in memory I'll need to just open part of it and run the rest of the code within the with:\n",
    "#seems to take some memory but not a lot. .12GB to load the other channel, but x 700 for the rest of the brain and its 84GB so it does load the whole thing probably or at least enough to mess things up\n",
    "#https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/\n",
    "\n",
    "with h5py.File(save_file_ch2, 'r') as hf:\n",
    "    data_ch1 = hf['zscore']\n",
    "    #test_get = hf['data']  #I think the [:] opens the dataset? I think it could also be done with [()]\n",
    "    #data_ch1 = hf['data'][:][...,0] #can slice like this to get first volume only\n",
    "    print(np.shape(data_ch1))\n",
    "#print(data_ch1.shape)\n",
    "# print(type(data_ch1))\n",
    "print(data_ch1)\n",
    "print(test_get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.12*700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 1.15GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "memory_usage = psutil.Process(os.getpid()).memory_info().rss*10**-9\n",
    "print('Current memory usage: {:.2f}GB'.format(memory_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 236, 29, 0)\n"
     ]
    }
   ],
   "source": [
    "## find a way to get dims of h5py without opening it\n",
    "dims = np.shape(data_ch1)\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 236, 29, 10)\n",
      "(476, 236, 29)\n",
      "(476, 236, 29)\n",
      "(476, 236, 29)\n",
      "smeanbrain (476, 236, 29)\n",
      "s-std (476, 236, 29)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##calculate meanbrain of moco brain\n",
    "dims = np.shape(data_ch1)\n",
    "print(dims)\n",
    "meanbrain = np.zeros(dims[:3])\n",
    "print(np.shape(meanbrain))\n",
    "print(np.shape(data_ch1[:,:,:,0]))\n",
    "print(dims[:3])\n",
    "for i in range(dims[-1]):  \n",
    "    meanbrain += data_ch1[:,:,:,i]\n",
    "meanbrain = meanbrain/small_brain_size\n",
    "print('smeanbrain', np.shape(meanbrain))\n",
    "\n",
    "##calculate STD of moco brain\n",
    "total = 0\n",
    "for i in range(dims[-1]):\n",
    "    s = (data_ch1[:,:,:,i] - meanbrain)**2\n",
    "    total = s + total\n",
    "final_std = np.sqrt(total/len(data_ch1[-1]))\n",
    "print('s-std', np.shape(final_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#run zscore\n",
    "for i in range(dims[-1]):\n",
    "    each_zscore = (data_ch1[:,:,:,i] - meanbrain)/final_std\n",
    "    \n",
    "    #save each zscore --use the same ch2 file and make a new key--need to set up the new key like did for moco\n",
    "    \n",
    "    \n",
    "    with h5py.File(save_file_ch2, 'a') as f_ch2:\n",
    "\n",
    "        # Increase hdf5 size by one brain volume\n",
    "        current_num_vol = f_ch2['zscore'].shape[-1] # this is the last axis, which is time\n",
    "        new_num_vol = current_num_vol + 1 # will want one more volume\n",
    "        f_ch2['zscore'].resize(new_num_vol,axis=3) # increase size by one volume\n",
    "\n",
    "        # Append to hdf5 file\n",
    "        f_ch2['zscore'][...,-1] = each_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 236, 29, 10)\n"
     ]
    }
   ],
   "source": [
    "## now do it inside the opening of the file \n",
    "## It's hard to know how to find the dims of the data\n",
    "#somehow I broke my data so it is only 1 volume..\n",
    "\n",
    "#make file to save into\n",
    "# with h5py.File(save_file_ch2, 'w') as f_ch2:\n",
    "#     zscore_ch2 = f_ch2.create_dataset('zscore test', (*dims[:3],0), maxshape=(*dims[:3],None), dtype='float32')\n",
    "# print('created empty hdf5 file ch2')\n",
    "\n",
    "#this is actually pretty fast for 10 volumes, I' not going to worry about doing chunks\n",
    "\n",
    "with h5py.File(save_file_ch2, 'a') as hf:  #I chagned this to a so I can read and write. Hopefully not a bad idea\n",
    "    #data_ch1 = hf['data'][:]\n",
    "    data_ch1 = hf['data']  #I think the [:] opens the dataset? I think it could also be done with [()]\n",
    "    #data_ch1 = hf['data'][:][...,0] #can slice like this to get first volume only\n",
    "    dims = np.shape(data_ch1)\n",
    "    print(dims)\n",
    "    \n",
    "    #make file to save zscore in (this errors if done more than once)\n",
    "    zscore_ch1 = hf.create_dataset('zscore test', (*dims[:3],0), maxshape=(*dims[:3],None), dtype='float32')\n",
    "\n",
    "\n",
    "    #find meanbrain (I want to run through the whole thing before moving to the zscore)\n",
    "    for i in range(dims[-1]):  \n",
    "        meanbrain += data_ch1[:,:,:,i]\n",
    "    meanbrain = meanbrain/small_brain_size\n",
    "\n",
    "    #find std\n",
    "    total = 0\n",
    "    for i in range(dims[-1]):\n",
    "        s = (data_ch1[:,:,:,i] - meanbrain)**2\n",
    "        total = s + total\n",
    "    final_std = np.sqrt(total/len(data_ch1[-1]))\n",
    "\n",
    "\n",
    "    #calculate zscore\n",
    "    for i in range(dims[-1]):\n",
    "        each_zscore = (data_ch1[:,:,:,i] - meanbrain)/final_std\n",
    "\n",
    "        #save zscore\n",
    "        # Increase hdf5 size by one brain volume\n",
    "        current_num_vol = hf['zscore test'].shape[-1] # this is the last axis, which is time\n",
    "        new_num_vol = current_num_vol + 1 # will want one more volume\n",
    "        hf['zscore test'].resize(new_num_vol,axis=3) # increase size by one volume\n",
    "\n",
    "        # Append to hdf5 file\n",
    "        hf['zscore test'][...,-1] = each_zscore\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
