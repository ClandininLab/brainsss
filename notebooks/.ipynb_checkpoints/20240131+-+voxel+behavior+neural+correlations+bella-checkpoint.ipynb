{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainsss\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.signal import butter, filtfilt, freqz\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import cm\n",
    "import random\n",
    "from scipy.stats import sem\n",
    "import time\n",
    "import h5py\n",
    "import ants\n",
    "import nibabel as nib\n",
    "import matplotlib\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fly_num = 'fly_194'\n",
    "func_path = f'/oak/stanford/groups/trc/data/Ilana/2P/data/{fly_num}/'\n",
    "# func_path = f'/oak/stanford/groups/trc/data/Brezovec/2P_Imaging/20190101_walking_dataset/{fly_num}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### PREP VISUAL STIMULI ###\n",
    "###########################\n",
    "\n",
    "vision_path = os.path.join(func_path,'func_0', 'visual')\n",
    "\n",
    "### Load Photodiode ###\n",
    "t, ft_triggers, pd1, pd2 = brainsss.load_photodiode(vision_path)\n",
    "stimulus_start_times = brainsss.extract_stim_times_from_pd(pd1, t)\n",
    "\n",
    "# *100 puts in units of 10ms, which will match fictrac\n",
    "st_10ms = [int(stimulus_start_times[i]*100) for i in range(len(stimulus_start_times))]\n",
    "\n",
    "# get 1ms version to match neural timestamps\n",
    "st_ms= [i*10 for i in st_10ms]\n",
    "starts_loom = st_10ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_start_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### Prep Fictrac ###\n",
    "####################\n",
    "\n",
    "fictrac_path = os.path.join(func_path, 'func_0', 'fictrac')\n",
    "fictrac_raw = brainsss.load_fictrac(fictrac_path)\n",
    "\n",
    "fps = 100\n",
    "resolution = 10 #desired resolution in ms\n",
    "expt_len = fictrac_raw.shape[0]/fps*1000\n",
    "behaviors = ['dRotLabY', 'dRotLabZ', 'dRotLabX']\n",
    "fictrac = {}\n",
    "for behavior in behaviors:\n",
    "    if behavior == 'dRotLabY': short = 'Y'\n",
    "    elif behavior == 'dRotLabZ': short = 'Z'\n",
    "    elif behavior == 'dRotLabX': short = 'X'\n",
    "    fictrac[short] = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior)\n",
    "fictrac_timestamps = np.arange(0,expt_len,resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fictrac_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#different way to smooth behavior\n",
    "\n",
    "# def smooth(x, axis=0, wid=5):\n",
    "#     # this is way faster than convolve, Minny smooth\n",
    "#     if wid < 2:\n",
    "#         return x\n",
    "#     cumsum_vec = np.cumsum(np.insert(x, 0, 0, axis=axis), axis=axis)\n",
    "#     ma_vec = (cumsum_vec[wid:] - cumsum_vec[:-wid]) / wid\n",
    "#     y = x.copy()\n",
    "#     start_ind = int(np.floor((wid-1)/2))\n",
    "#     end_ind = wid-1-start_ind\n",
    "#     y[start_ind:-end_ind] = ma_vec\n",
    "#     return y\n",
    "\n",
    "# def smooth_vel(X, Y, theta, width=0):\n",
    "#     # Alex smooth\n",
    "#     N = np.size(X)\n",
    "    \n",
    "#     sX = smooth(X, axis=0, wid=width)\n",
    "#     sY = smooth(Y, axis=0, wid=width)\n",
    "    \n",
    "    \n",
    "#     Fwd = np.zeros((N), dtype=float)\n",
    "#     Slid = np.zeros((N), dtype=float)\n",
    "    \n",
    "#     for i in range(1,N):\n",
    "#         dx = sX[i]-sX[i-1]\n",
    "#         dy = sY[i]-sY[i-1]\n",
    "#         tz = theta[i-1]\n",
    "#         Fwd[i] = dx*np.cos(tz) + dy*np.sin(tz)\n",
    "#         Slid[i] = dx*np.sin(tz) - dy*np.cos(tz)\n",
    "#     return Fwd, Slid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_traces(fictrac, stim_times, pre_window, post_window, val=None):\n",
    "    traces = []\n",
    "    for i in range(len(stim_times)):\n",
    "        if val != None:\n",
    "            trace = fictrac[val][stim_times[i]-pre_window:stim_times[i]+post_window]\n",
    "        else:\n",
    "            trace = fictrac[stim_times[i]-pre_window:stim_times[i]+post_window]\n",
    "        if len(trace) == pre_window + post_window: # this handles fictrac that crashed or was aborted or some bullshit\n",
    "            traces.append(trace)\n",
    "    traces = np.asarray(traces)\n",
    "    mean_trace = np.mean(traces,axis=0)\n",
    "    sem_trace = scipy.stats.sem(traces,axis=0)\n",
    "    return traces, mean_trace, sem_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#next two cells made for 10min fictrac cut off\n",
    "\n",
    "weird_size = np.size(fictrac['Y'])\n",
    "weird_idx = list(np.where(np.asarray(starts_loom) <= weird_size)[0])\n",
    "actual_looms = np.asarray(starts_loom)[weird_idx]\n",
    "\n",
    "actual_looms_ms = [i*10 for i in actual_looms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fictrac['Y'])\n",
    "for i in range(len(actual_looms)):\n",
    "    plt.axvline(actual_looms[i], color='r')\n",
    "# plt.xlim(starts_loom[0], starts_loom[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#QC to check if flies actually responding to loom\n",
    "max_time = np.max(actual_looms)\n",
    "min_time = 0\n",
    "null_times = np.random.randint(min_time, max_time, len(actual_looms))\n",
    "# this replaces starts_loom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "### Extract Stimulus Triggered Behavior ###\n",
    "###########################################\n",
    "\n",
    "pre_window = 200\n",
    "post_window = 300\n",
    "# avg_around = 20\n",
    "# stim_time = 75\n",
    "# window = np.arange(-pre_window,post_window)\n",
    "\n",
    "behavior_traces = {}\n",
    "mean_trace = {}\n",
    "sem_trace = {}\n",
    "behavior_traces,mean_trace,sem_trace = extract_traces(fictrac['Y'], actual_looms, pre_window, post_window)\n",
    "behavior_traces_QC,mean_trace_QC,sem_trace_QC = extract_traces(fictrac['Y'], null_times, pre_window, post_window)\n",
    "# behavior_traces_x,mean_trace,sem_trace = extract_traces(fictrac, starts_loom, pre_window, post_window, 'X')\n",
    "# behavior_traces_z,mean_trace,sem_trace = extract_traces(fictrac, starts_loom, pre_window, post_window, 'Z')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(mean_trace,color='k',linewidth=3)\n",
    "plt.fill_between(np.arange(len(mean_trace)),mean_trace-sem_trace, mean_trace+sem_trace, color='k',alpha=0.3)\n",
    "plt.axvline(200,color='k',linestyle='--',lw=2)\n",
    "plt.axvline(300,color='k',linestyle='--',lw=2)\n",
    "plt.ylim(-1, 5);\n",
    "\n",
    "#null_hypothesis check\n",
    "# plt.plot(mean_trace_QC,color='b',linewidth=3)\n",
    "# plt.fill_between(np.arange(len(mean_trace_QC)),mean_trace_QC-sem_trace_QC, mean_trace_QC+sem_trace_QC, color='b',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.shape(behavior_traces)\n",
    "# rand_time_e = 250\n",
    "# rand_time_s = 210\n",
    "# diffs = behavior_traces[:,rand_time_e]-behavior_traces[:,rand_time_s]\n",
    "# diffs_QC = behavior_traces_QC[:,rand_time_e]-behavior_traces_QC[:,rand_time_s]\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.hist(diffs)\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.hist(diffs_QC)\n",
    "# # a randomly chosen location after loom to compare the speeds--consider changing this val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = fictrac_raw[\"timeStamp\"] #in ns i think\n",
    "ts_sec = ts/1e9\n",
    "fr = 1/np.mean(np.diff(ts_sec)) #figure out frame_rate from bruker fictrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# andrew anaylsis\n",
    "value_struct ={\n",
    "    # the data is in 10ms, use this value to get the index if i use seconds\n",
    "    \"tp_width_sec\": 0.01,\n",
    "    \"trial_time_sec\": 1,\n",
    "    \"before_stim_sec\": pre_window/100,\n",
    "    # time in seconds between end of pre trial window and the stimulus time. \n",
    "    # when set to zero, the pre trial window ends when the stimulus is presented\n",
    "    \"pre_trial_window_sec\": -0.05,\n",
    "    # size of window that pre trial speed is averaged over, seconds, window ends at stimulus time\n",
    "    # when 0 is a single val and not a window\n",
    "    \"pre_trial_size_sec\": 0,\n",
    "    # size of post trial speed average window, sec\n",
    "    \"post_trial_window_sec\": 0.5,\n",
    "    # post trial window at stim tiem + post trail delay\n",
    "    # when 0 is a single val and not a window\n",
    "    \"post_trial_size_sec\": 0,\n",
    "    \"thresh\": 0.05\n",
    "    }\n",
    "def get_vals_for_analysis(tp_width_sec=0, trial_time_sec=0, before_stim_sec=0, pre_trial_window_sec=0, pre_trial_size_sec=0, post_trial_window_sec=0, post_trial_size_sec=0, thresh=0):\n",
    "        \n",
    "    stim_end_sec = before_stim_sec + trial_time_sec\n",
    "    \n",
    "    stim_idx = int(before_stim_sec/tp_width_sec)\n",
    "    stim_end_idx = int(stim_end_sec/tp_width_sec)\n",
    "    pre_trial_window_idx = int(pre_trial_window_sec/tp_width_sec)\n",
    "\n",
    "    # first val i use to make delta to compare change in vel\n",
    "    first_val_end_idx = int(stim_idx - pre_trial_window_idx)\n",
    "    first_val_start_idx = int(first_val_end_idx - (pre_trial_size_sec/tp_width_sec)) #only needed if you're averaging across a window, otherwise just start val is used\n",
    "\n",
    "    # second val used to make delta\n",
    "    second_val_start_idx = int(stim_idx + post_trial_size_sec/tp_width_sec)\n",
    "    second_val_end_idx = int(second_val_start_idx + post_trial_window_sec/tp_width_sec)\n",
    "    return stim_idx, stim_end_idx, pre_trial_window_idx, first_val_end_idx, first_val_start_idx, second_val_end_idx, second_val_start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = filtfilt(b, a, data, method=\"gust\")\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_butter_lowpass(behavior_traces, stim_idx, fr):\n",
    "    # Filter requirements.\n",
    "    order = 4\n",
    "    fs = fr      # sample rate, Hz\n",
    "    cutoff = 3  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "    # Get the filter coefficients so we can check its frequency response.\n",
    "    b, a = butter_lowpass(cutoff, fs, order)\n",
    "\n",
    "    # Plot the frequency response.\n",
    "    w, h = freqz(b, a, fs=fs, worN=8000)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(w, np.abs(h), 'b')\n",
    "    plt.plot(cutoff, 0.5*np.sqrt(2), 'ko')\n",
    "    plt.axvline(cutoff, color='k')\n",
    "    plt.xlim(0, 0.5*fs)\n",
    "    plt.title(\"Lowpass Filter Frequency Response\")\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    # plt.grid()\n",
    "\n",
    "    # Filter the data, and plot both the original and filtered signals.\n",
    "    lpf_behavior = np.zeros((behavior_traces.shape[0], behavior_traces.shape[1] - stim_idx))\n",
    "\n",
    "    for i in range(behavior_traces.shape[0]):\n",
    "        lpf_behavior[i, :] = butter_lowpass_filter(behavior_traces[i,stim_idx:], cutoff, fs, order)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(np.mean(behavior_traces[:, stim_idx:], axis=0), 'b-', label='data')\n",
    "    plt.plot(np.mean(lpf_behavior, axis=0), 'g-', linewidth=2, label='filtered data')\n",
    "    # plt.plot(np.mean(lpf_behavior_QC, axis=0), 'r-', linewidth=2, label='QC filtered data')\n",
    "    plt.xlabel('Time')\n",
    "    # plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    plt.show()\n",
    "    return lpf_behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_speed_change(behavior, stim_idx, first_val_start_idx, first_val_end_idx, second_val_start_idx, second_val_end_idx):\n",
    "    pre_tsi= first_val_start_idx-stim_idx\n",
    "    pre_tei = first_val_end_idx-stim_idx\n",
    "    post_tsi = second_val_start_idx-stim_idx\n",
    "    post_tei = second_val_end_idx-stim_idx\n",
    "    \n",
    "    if first_val_start_idx!=first_val_end_idx:\n",
    "        first_speed = np.mean(behavior[:,pre_tsi:pre_tei], axis = 1)\n",
    "    else:\n",
    "        first_val_start_idx = int(first_val_start_idx)\n",
    "        first_speed = np.asarray(behavior[:,pre_tsi])\n",
    "\n",
    "    if second_val_start_idx!=second_val_end_idx:\n",
    "        second_speed = np.mean(behavior[:,post_tsi:post_tei], axis = 1)\n",
    "    else: \n",
    "        second_speed = np.asarray(behavior[:,post_tsi])\n",
    "    speed_change = second_speed-first_speed\n",
    "    return speed_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trials(speed_change, thresh):\n",
    "    decrease_trials = speed_change <-thresh\n",
    "    decrease_idx = np.where(decrease_trials)\n",
    "    increase_trials = speed_change>thresh\n",
    "    increase_idx = np.where(increase_trials)\n",
    "    flat_trials = np.logical_and(speed_change>-thresh, speed_change<thresh)\n",
    "    flat_idx = np.where(flat_trials)\n",
    "    return increase_trials, decrease_trials, flat_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def validate_trial(trial_idx, trace=None):\n",
    "    \"\"\" Visualize a single trial, along with the pre and post averaging windows\n",
    "    \n",
    "    RED: pre window\n",
    "    YELLOW: post window\n",
    "    BLUE: stim time\n",
    "    \"\"\"\n",
    "    if trace is None:\n",
    "        trace = behavior_traces[trial_idx]\n",
    "    plt.plot(trace)\n",
    "    plt.axvline(first_val_start_idx, color='r')\n",
    "    plt.axvline(first_val_end_idx, color='r')\n",
    "    plt.axvline(second_val_start_idx, color='y')\n",
    "    plt.axvline(second_val_end_idx, color='y')\n",
    "    plt.axvline(stim_idx, color='b')\n",
    "\n",
    "\n",
    "def validate_windows(behavior_traces, value_struct, fr):\n",
    "    \"\"\" Visualize average traces for both slow and fast trials\n",
    "    \n",
    "    NOTE: uses global variables, must rerun constant cells and slow_ind logic to change results.\n",
    "    \n",
    "    RED: pre window\n",
    "    YELLOW: post window\n",
    "    BLUE: stim time\n",
    "    \"\"\"\n",
    "    \n",
    "    stim_idx, stim_end_idx, pre_trial_window_idx, first_val_end_idx, first_val_start_idx, second_val_end_idx, second_val_start_idx = get_vals_for_analysis(**value_struct)\n",
    "    lpf_behavior = apply_butter_lowpass(behavior_traces, stim_idx, fr)\n",
    "    speed_change = get_speed_change(lpf_behavior, stim_idx, first_val_start_idx, first_val_end_idx, second_val_start_idx, second_val_end_idx)\n",
    "    increase_trials, decrease_trials, flat_trials = get_trials(speed_change, value_struct[\"thresh\"])\n",
    "    increase_traces = behavior_traces[increase_trials]\n",
    "    decrease_traces = behavior_traces[decrease_trials]\n",
    "    flat_traces = behavior_traces[flat_trials]\n",
    "    \n",
    "    print(f\"{len(increase_traces)} increase trials\")\n",
    "    print(f\"{len(decrease_traces)} decrease trials\")\n",
    "    print(f\"{len(flat_traces)} flat trials\")\n",
    "    \n",
    "    increase_mean = np.mean(increase_traces, axis=0)\n",
    "    increase_sem = scipy.stats.sem(increase_traces, axis=0)\n",
    "    \n",
    "    decrease_mean = np.mean(decrease_traces, axis=0)\n",
    "    decrease_sem = scipy.stats.sem(decrease_traces, axis=0)\n",
    "    \n",
    "    flat_mean = np.mean(flat_traces, axis=0)\n",
    "    flat_sem = scipy.stats.sem(flat_traces, axis=0)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3)\n",
    "    \n",
    "    axes[0].plot(increase_mean, color='k',linewidth=3)\n",
    "    axes[0].set_ylim(-1, 3.5)\n",
    "    axes[0].fill_between(np.arange(len(increase_mean)), increase_mean - increase_sem, increase_mean + increase_sem, color='k',alpha=0.3)\n",
    "    axes[0].axvline(first_val_start_idx, color='r')\n",
    "    axes[0].axvline(first_val_end_idx, color='r')\n",
    "    axes[0].axvline(second_val_start_idx, color='y')\n",
    "    axes[0].axvline(second_val_end_idx, color='y')\n",
    "    axes[0].axvline(stim_idx, color='b', linestyle='--')\n",
    "    axes[0].axvline(stim_end_idx, color='b', linestyle='--')\n",
    "#     axes[0].set_title(\"slow trials\")\n",
    "    \n",
    "\n",
    "    \n",
    "    axes[1].plot(decrease_mean, color='k',linewidth=3)\n",
    "    axes[1].set_ylim(-1, 3.5)\n",
    "    axes[1].fill_between(np.arange(len(decrease_mean)), decrease_mean - decrease_sem, decrease_mean + decrease_sem, color='k',alpha=0.3)\n",
    "    axes[1].axvline(first_val_start_idx, color='r')\n",
    "    axes[1].axvline(first_val_end_idx, color='r')\n",
    "    axes[1].axvline(second_val_start_idx, color='y')\n",
    "    axes[1].axvline(second_val_end_idx, color='y')\n",
    "    axes[1].axvline(stim_idx, color='b', linestyle='--')\n",
    "    axes[1].axvline(stim_end_idx, color='b', linestyle='--')\n",
    "    \n",
    "    axes[2].plot(flat_mean, color='k',linewidth=3)\n",
    "    axes[2].set_ylim(-1, 3.5)\n",
    "    axes[2].fill_between(np.arange(len(flat_mean)), flat_mean - flat_sem, flat_mean + flat_sem, color='k',alpha=0.3)\n",
    "    axes[2].axvline(first_val_start_idx, color='r')\n",
    "    axes[2].axvline(first_val_end_idx, color='r')\n",
    "    axes[2].axvline(second_val_start_idx, color='y')\n",
    "    axes[2].axvline(second_val_end_idx, color='y')\n",
    "    axes[2].axvline(stim_idx, color='b', linestyle='--')\n",
    "    axes[2].axvline(stim_end_idx, color='b', linestyle='--')\n",
    "    \n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = validate_windows(behavior_traces_QC,value_struct, fr)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = validate_windows(behavior_traces, value_struct, fr)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 2000\n",
    "cluster_dir = os.path.join(func_path, 'func_0','clustering')\n",
    "\n",
    "load_file = os.path.join(cluster_dir, 'cluster_labels.npy')\n",
    "cluster_labels = np.load(load_file)\n",
    "\n",
    "load_file = os.path.join(cluster_dir, 'cluster_signals.npy')\n",
    "all_signals = np.load(load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(all_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_average =np.mean(all_signals, axis=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fictrac checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fictrac['Y'] = np.squeeze(fictrac['Y'])\n",
    "out = scipy.signal.correlate(time_average, fictrac['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(out)\n",
    "plt.axvline(3384,color='k')\n",
    "plt.xlim(3300,3400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check warp quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed = brainsss.load_fda_meanbrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas = brainsss.load_roi_atlas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explosion_rois = brainsss.load_explosion_groups()\n",
    "all_rois = brainsss.unnest_roi_groups(explosion_rois)\n",
    "roi_masks = brainsss.make_single_roi_masks(all_rois, atlas)\n",
    "roi_contours = brainsss.make_single_roi_contours(roi_masks, atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = brainsss.load_timestamps(os.path.join(func_path,'func_0', 'imaging'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_dir = os.path.join(func_path, 'warp')\n",
    "f2a = ants.image_read(os.path.join(warp_dir, 'func-to-anat.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(f2a[:,:,70].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2a = ants.image_read(os.path.join(warp_dir, 'anat-to-meanbrain.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anat_dir = os.path.join(func_path, 'anat_0', 'moco')\n",
    "anat = ants.image_read(os.path.join(anat_dir, 'anatomy_channel_1_moc_mean.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anat.set_spacing((0.653, 0.653, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anat_low=anat.resample_image((2,2,2),use_voxels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(a2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=20\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(a2a[:,:,z].T)\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(fixed[:,:,z].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_start = -500; bin_end = 2000; bin_size = 100 #ms\n",
    "neural_bins = np.arange(bin_start,bin_end,bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####CHANGE BEHAVIOR!!!\n",
    "# behavior_traces = behavior_traces\n",
    "behavior_traces = behavior_traces_QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_idx, stim_end_idx, pre_trial_window_idx, first_val_end_idx, first_val_start_idx, second_val_end_idx, second_val_start_idx = get_vals_for_analysis(**value_struct)\n",
    "lpf_behavior = apply_butter_lowpass(behavior_traces, stim_idx, fr)\n",
    "speed_change = get_speed_change(lpf_behavior, stim_idx, first_val_start_idx, first_val_end_idx, second_val_start_idx, second_val_end_idx)\n",
    "increase_trials, decrease_trials, flat_trials = get_trials(speed_change, value_struct[\"thresh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_event_times_list(trials, event_times, ms=True):\n",
    "    trials_idx = np.where(trials)\n",
    "    trials_starts =[]\n",
    "    for idx in trials_idx[0]:\n",
    "        trials_starts.append(event_times[idx])\n",
    "    if ms==True:\n",
    "        trials_starts = [n*10 for n in trials_starts]\n",
    "    print(np.shape(trials_starts))\n",
    "    return trials_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For regular data\n",
    "# decrease_starts_ms = get_event_times_list(decrease_trials, actual_looms, ms=True)\n",
    "# increase_starts_ms = get_event_times_list(increase_trials, actual_looms, ms=True)\n",
    "# flat_starts_ms = get_event_times_list(flat_trials, actual_looms, ms=True)\n",
    "\n",
    "# For QC data\n",
    "decrease_starts_ms = get_event_times_list(decrease_trials, null_times, ms=True)\n",
    "increase_starts_ms = get_event_times_list(increase_trials, null_times, ms=True)\n",
    "flat_starts_ms = get_event_times_list(flat_trials, null_times, ms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "STA_brain_decrease = brainsss.make_STA_brain(neural_signals = all_signals,\n",
    "                                   neural_timestamps = timestamps,\n",
    "                                   event_times_list = decrease_starts_ms,\n",
    "                                   neural_bins = neural_bins)\n",
    "\n",
    "STA_brain_increase = brainsss.make_STA_brain(neural_signals = all_signals,\n",
    "                                   neural_timestamps = timestamps,\n",
    "                                   event_times_list = increase_starts_ms,\n",
    "                                   neural_bins = neural_bins)\n",
    "\n",
    "STA_brain_flat = brainsss.make_STA_brain(neural_signals = all_signals,\n",
    "                                   neural_timestamps = timestamps,\n",
    "                                   event_times_list = flat_starts_ms,\n",
    "                                   neural_bins = neural_bins)\n",
    "print(F'STA {time.time()-t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USE THIS FOR CORR\n",
    "\n",
    "def make_STA_brain_corr(neural_signals, neural_timestamps, event_times_list, neural_bins):\n",
    "    #### super voxel version\n",
    "\n",
    "    STA_brain = []\n",
    "    for z in range(49):\n",
    "        print(z)\n",
    "        ### interpolate behavior to neural data\n",
    "        #https://github.com/ClandininLab/brainsss/blob/main/scripts/correlation.py\n",
    "        behavior = 'dRotLabY'\n",
    "        fictrac_interp = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior, timestamps=timestamps, z=z)\n",
    "        \n",
    "        all_bin_indicies = []\n",
    "        for stim_idx in range(len(event_times_list)):\n",
    "            stim_time = event_times_list[stim_idx]\n",
    "            stim_centered_bins = neural_bins + stim_time\n",
    "            bin_indicies = np.digitize(neural_timestamps[:,z] , stim_centered_bins)\n",
    "            all_bin_indicies.append(bin_indicies)\n",
    "        all_bin_indicies = np.asarray(all_bin_indicies)\n",
    "\n",
    "        avg_neural_across_bins = []\n",
    "        for bin_num in np.arange(1,len(neural_bins)):\n",
    "            this_bin_sample_times = list(np.where(all_bin_indicies==bin_num)[1])\n",
    "            \n",
    "            neural_data_points = neural_signals[z,:,this_bin_sample_times]\n",
    "            behavior_data_points = fictrac_interp[this_bin_sample_times]\n",
    "            \n",
    "            corr = []\n",
    "            for cluster in range(2000):\n",
    "                corr.append(scipy.stats.pearsonr(behavior_data_points, neural_data_points[:,cluster])[0])\n",
    "            corr = np.asarray(corr)\n",
    "            \n",
    "            avg_neural_across_bins.append(corr)\n",
    "        avg_neural_across_bins = np.asarray(avg_neural_across_bins)\n",
    "        STA_brain.append(avg_neural_across_bins)\n",
    "    STA_brain = np.asarray(STA_brain)\n",
    "    return STA_brain\n",
    "\n",
    "corr_brain = make_STA_brain_corr(neural_signals = all_signals,\n",
    "                                   neural_timestamps = timestamps,\n",
    "                                   event_times_list = actual_looms_ms, #### FIX THIS? ms.\n",
    "                                   neural_bins = neural_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_signals = all_signals\n",
    "neural_timestamps = timestamps\n",
    "event_times_list = actual_looms_ms\n",
    "neural_bins = neural_bins\n",
    "            \n",
    "z=20\n",
    "### interpolate behavior to neural data\n",
    "#https://github.com/ClandininLab/brainsss/blob/main/scripts/correlation.py\n",
    "behavior = 'dRotLabY'\n",
    "fictrac_interp = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior, timestamps=timestamps, z=z)\n",
    "\n",
    "all_bin_indicies = []\n",
    "for stim_idx in range(len(event_times_list)):\n",
    "    stim_time = event_times_list[stim_idx]\n",
    "    stim_centered_bins = neural_bins + stim_time\n",
    "    bin_indicies = np.digitize(neural_timestamps[:,z] , stim_centered_bins)\n",
    "    all_bin_indicies.append(bin_indicies)\n",
    "all_bin_indicies = np.asarray(all_bin_indicies)\n",
    "\n",
    "avg_neural_across_bins = []\n",
    "for bin_num in np.arange(1,len(neural_bins)):\n",
    "    this_bin_sample_times = list(np.where(all_bin_indicies==bin_num)[1])\n",
    "\n",
    "    neural_data_points = neural_signals[z,:,this_bin_sample_times]\n",
    "    behavior_data_points = fictrac_interp[this_bin_sample_times]\n",
    "\n",
    "    corr = []\n",
    "    for cluster in range(2000):\n",
    "        corr.append(scipy.stats.pearsonr(behavior_data_points, neural_data_points[:,cluster])[0])\n",
    "    corr = np.asarray(corr)\n",
    "\n",
    "    avg_neural_across_bins.append(corr)\n",
    "avg_neural_across_bins = np.asarray(avg_neural_across_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(behavior_data_points, neural_data_points[:,cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_data_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reformed_STA_brain_decrease = brainsss.STA_supervoxel_to_full_res(STA_brain_decrease, cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 2000\n",
    "n_tp = 24\n",
    "\n",
    "colored_by_betas = np.zeros((n_tp, 256*128))\n",
    "for cluster_num in range(n_clusters):\n",
    "    cluster_indicies = np.where(cluster_labels[z,:]==cluster_num)[0]\n",
    "    colored_by_betas[:,cluster_indicies] = avg_neural_across_bins[:,cluster_num,np.newaxis]\n",
    "colored_by_betas = colored_by_betas.reshape(n_tp,256,128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colored_by_betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(colored_by_betas[7,:,:,].T)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_neural_across_bins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_brain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(avg_neural_across_bins[7,:],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_brain = np.nan_to_num(corr_brain)\n",
    "reformed_corr_brain = brainsss.STA_supervoxel_to_full_res(corr_brain, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STA_brain = gaussian_filter1d(reformed_corr_brain,sigma=1,axis=1,truncate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STA_brain_decrease = np.nan_to_num(STA_brain_decrease)\n",
    "STA_brain_increase = np.nan_to_num(STA_brain_increase)\n",
    "STA_brain_flat = np.nan_to_num(STA_brain_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reformed_STA_brain_decrease = brainsss.STA_supervoxel_to_full_res(STA_brain_decrease, cluster_labels)\n",
    "reformed_STA_brain_increase = brainsss.STA_supervoxel_to_full_res(STA_brain_increase, cluster_labels)\n",
    "reformed_STA_brain_flat = brainsss.STA_supervoxel_to_full_res(STA_brain_flat, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(reformed_STA_brain_decrease[25,15,:,:].T,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change the STA brain based on condition\n",
    "STA_brain = gaussian_filter1d(reformed_STA_brain_flat,sigma=1,axis=1,truncate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STA_brain will be (bins,x,t,z) or (20,256,128,49)\n",
    "#what you want now is (n,256,128,49), where n is number of looms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp_STA_brain(STA_brain, fly, fixed, anat_to_mean_type, func_path):\n",
    "    n_tp = STA_brain.shape[1]\n",
    "    moving_resolution = (2.611, 2.611, 5)\n",
    "    ###########################\n",
    "    ### Organize Transforms ###\n",
    "    ###########################\n",
    "    warp_directory = os.path.join(func_path,'warp')\n",
    "    warp_sub_dir = 'func-to-anat_fwdtransforms_2umiso'\n",
    "    affine_file = os.listdir(os.path.join(warp_directory, warp_sub_dir))[0]\n",
    "    affine_path = os.path.join(warp_directory, warp_sub_dir, affine_file)\n",
    "    if anat_to_mean_type == 'myr':\n",
    "        warp_sub_dir = 'anat-to-meanbrain_fwdtransforms_2umiso'\n",
    "    elif anat_to_mean_type == 'non_myr':\n",
    "        warp_sub_dir = 'anat-to-non_myr_mean_fwdtransforms_2umiso'\n",
    "    else:\n",
    "        print('invalid anat_to_mean_type')\n",
    "        return\n",
    "    syn_files = os.listdir(os.path.join(warp_directory, warp_sub_dir))\n",
    "    syn_linear_path = os.path.join(warp_directory, warp_sub_dir, [x for x in syn_files if '.mat' in x][0])\n",
    "    syn_nonlinear_path = os.path.join(warp_directory, warp_sub_dir, [x for x in syn_files if '.nii.gz' in x][0])\n",
    "    ####transforms = [affine_path, syn_linear_path, syn_nonlinear_path]\n",
    "    transforms = [syn_nonlinear_path, syn_linear_path, affine_path] ### INVERTED ORDER ON 20220503!!!!\n",
    "    #ANTS DOCS ARE SHIT. THIS IS PROBABLY CORRECT, AT LEAST IT NOW WORKS FOR THE FLY(134) THAT WAS FAILING\n",
    "\n",
    "\n",
    "    ### Warp timeponts\n",
    "    warps = []\n",
    "    for tp in range(n_tp):\n",
    "        to_warp = np.rollaxis(STA_brain[:,tp,:,:],0,3)\n",
    "        moving = ants.from_numpy(to_warp)\n",
    "        moving.set_spacing(moving_resolution)\n",
    "        ########################\n",
    "        ### Apply Transforms ###\n",
    "        ########################\n",
    "        moco = ants.apply_transforms(fixed, moving, transforms)\n",
    "        warped = moco.numpy()\n",
    "        warps.append(warped)\n",
    "\n",
    "    return warps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "warps = warp_STA_brain(STA_brain=STA_brain, fly=fly_num, fixed=fixed, anat_to_mean_type='myr', func_path=func_path)\n",
    "print(F'Warps {time.time()-t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_roi_signal_traces(roi_ids, roi_masks, warps, hemi, signal_type):\n",
    "    t0 = time.time()\n",
    "    roi_time_avgs = []\n",
    "    for roi in roi_ids[hemi]:\n",
    "        mask = roi_masks[roi]\n",
    "        masked_data = warps[:,:,:,:]*mask[np.newaxis,:,:,:] #note z-flip\n",
    "        if signal_type == 'max':\n",
    "            roi_time_avg = np.max(masked_data,axis=(1,2,3))\n",
    "        elif signal_type == 'mean':\n",
    "            roi_time_avg = np.mean(masked_data,axis=(1,2,3))\n",
    "        roi_time_avgs.append(roi_time_avg)\n",
    "    print(time.time()-t0)\n",
    "    return np.asarray(roi_time_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explosions = []\n",
    "t0 = time.time()\n",
    "for tp in range(24):\n",
    "    input_canvas = np.ones((500,500,3)) #+.5 #.5 for diverging\n",
    "    data_to_plot = warps[tp][:,:,::-1]\n",
    "    vmax = 0.5 #this was 0.5 for STA <------------\n",
    "    explosion_map = brainsss.place_roi_groups_on_canvas(explosion_rois,\n",
    "                                                        roi_masks,\n",
    "                                                        roi_contours,\n",
    "                                                        data_to_plot,\n",
    "                                                        input_canvas,\n",
    "                                                        vmax=vmax,\n",
    "                                                        cmap='seismic', diverging=True)#'hot')\n",
    "    explosions.append(explosion_map)\n",
    "print(F'Explosion {time.time()-t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "plt.imshow(explosions[i][170:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dir = os.path.join(func_path, 'movies')\n",
    "if os.path.exists(movie_dir)==False:\n",
    "    os.mkdir(movie_dir)\n",
    "print(movie_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(movie_dir,'flat_QC')\n",
    "if os.path.exists(save_dir)==False:\n",
    "    os.mkdir(save_dir)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(24):\n",
    "    print(i)\n",
    "    plt.imshow(explosions[i][170:,:]) #this was made with cmap=hot\n",
    "    fname = os.path.join(save_dir, '{0:05d}.png'.format(i))\n",
    "    plt.savefig(fname,dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_STA_brain(neural_signals, neural_timestamps, event_times_list, neural_bins):\n",
    "    #### super voxel version\n",
    "    \n",
    "    STA_brain = []\n",
    "    for z in range(49):\n",
    "        all_bin_indicies = []\n",
    "        for stim_idx in range(len(event_times_list)):\n",
    "            stim_time = event_times_list[stim_idx]\n",
    "            stim_centered_bins = neural_bins + stim_time\n",
    "            bin_indicies = np.digitize(neural_timestamps[:,z] , stim_centered_bins)\n",
    "            all_bin_indicies.append(bin_indicies)\n",
    "        all_bin_indicies = np.asarray(all_bin_indicies)\n",
    "\n",
    "        avg_neural_across_bins = []\n",
    "        for bin_num in np.arange(1,len(neural_bins)):\n",
    "            this_bin_sample_times = list(np.where(all_bin_indicies==bin_num)[1])\n",
    "            average_neural_in_bin = np.mean(neural_signals[z,:,this_bin_sample_times],axis=0)\n",
    "            avg_neural_across_bins.append(average_neural_in_bin)\n",
    "        avg_neural_across_bins = np.asarray(avg_neural_across_bins)\n",
    "        STA_brain.append(avg_neural_across_bins)\n",
    "    STA_brain = np.asarray(STA_brain)\n",
    "    return STA_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for z in range(1): \n",
    "    all_bin_indicies = []\n",
    "    for stim_idx in range(len(starts_loom_ms)):\n",
    "        stim_time = starts_loom_ms[stim_idx]\n",
    "        stim_centered_bins = neural_bins + stim_time\n",
    "        bin_indicies = np.digitize(timestamps[:,z] , stim_centered_bins)\n",
    "        all_bin_indicies.append(bin_indicies)\n",
    "    all_bin_indicies = np.asarray(all_bin_indicies)\n",
    "\n",
    "    avg_neural_across_bins = []\n",
    "    for bin_num in np.arange(1,len(neural_bins)):\n",
    "        this_bin_sample_times = list(np.where(all_bin_indicies==bin_num)[1])\n",
    "        print(np.shape(this_bin_sample_times))\n",
    "        average_neural_in_bin = np.mean(all_signals[z,:,this_bin_sample_times],axis=0)\n",
    "        avg_neural_across_bins.append(average_neural_in_bin)\n",
    "    avg_neural_across_bins = np.asarray(avg_neural_across_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "behavior = 'dRotLabY'\n",
    "fictrac_interp = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior, timestamps=timestamps, z=z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for z in range(1): \n",
    "    \n",
    "    ### interpolate behavior to neural data\n",
    "    #https://github.com/ClandininLab/brainsss/blob/main/scripts/correlation.py\n",
    "    behavior = 'dRotLabY'\n",
    "    fictrac_interp = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior, timestamps=timestamps, z=z)\n",
    "    \n",
    "    all_bin_indicies = []\n",
    "    for stim_idx in range(len(starts_loom_ms)):\n",
    "        stim_time = starts_loom_ms[stim_idx]\n",
    "        stim_centered_bins = neural_bins + stim_time\n",
    "        bin_indicies = np.digitize(timestamps[:,z] , stim_centered_bins)\n",
    "        all_bin_indicies.append(bin_indicies)\n",
    "    all_bin_indicies = np.asarray(all_bin_indicies)\n",
    "\n",
    "    avg_neural_across_bins = []\n",
    "    for bin_num in np.arange(1,len(neural_bins)):\n",
    "        this_bin_sample_times = list(np.where(all_bin_indicies==bin_num)[1])\n",
    "        print(np.shape(this_bin_sample_times))\n",
    "        #average_neural_in_bin = np.mean(all_signals[z,:,this_bin_sample_times],axis=0)\n",
    "        neural_data_points = all_signals[z,:,this_bin_sample_times]\n",
    "        behavior_data_points = fictrac_interp[this_bin_sample_times]\n",
    "        \n",
    "        corr = scipy.stats.pearsonr(behavior_data_points, neural_data_points)[0]\n",
    "        avg_neural_across_bins.append(corr)\n",
    "    avg_neural_across_bins = np.asarray(avg_neural_across_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(timestamps))\n",
    "print(np.shape(all_bin_indicies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "STA_brain = brainsss.make_STA_brain(neural_signals = all_signals,\n",
    "                                   neural_timestamps = timestamps,\n",
    "                                   event_times_list = starts_loom_ms,\n",
    "                                   neural_bins = neural_bins)\n",
    "\n",
    "print(F'STA {time.time()-t0}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
