{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy\n",
    "import nibabel as nib\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import brainsss\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import ants\n",
    "# import bigbadbrain as bbb\n",
    "# from scipy.ndimage.filters import gaussian_filter\n",
    "# from scipy.signal import savgol_filter\n",
    "# from scipy.interpolate import interp1d\n",
    "\n",
    "# from skimage.filters import threshold_triangle\n",
    "# sys.path.insert(0, '/home/users/brezovec/.local/lib/python3.6/site-packages')\n",
    "# import os\n",
    "# import statsmodels.api as sm\n",
    "# import cv2\n",
    "# import matplotlib.patches as mpatches\n",
    "# import psutil\n",
    "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "# from matplotlib.colors import Normalize\n",
    "# plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# from sklearn.feature_extraction.image import grid_to_graph\n",
    "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "# import json\n",
    "# from matplotlib.ticker import FuncFormatter\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "# import itertools\n",
    "# import random\n",
    "# from scipy.cluster import hierarchy\n",
    "# from matplotlib.pyplot import cm\n",
    "\n",
    "# from scipy.interpolate import UnivariateSpline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# import pickle\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.linear_model import RidgeCV\n",
    "# from sklearn.linear_model import LassoCV\n",
    "# from sklearn.linear_model import Ridge\n",
    "# import pickle\n",
    "\n",
    "# from scipy.ndimage.morphology import binary_erosion\n",
    "# from scipy.ndimage.morphology import binary_dilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visual.py from github\n",
    "def pd_csv_to_h5py(directory, file):\n",
    "\t\"\"\" Loads photodiode data from csv file and saves to h5py file.\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdirectory: full path to vision folder\n",
    "\tfile: csv file\n",
    "\tReturns\n",
    "\t-------\n",
    "\tNothing. \"\"\"\n",
    "\n",
    "\tprint('loading raw photodiode data... ',end='')\n",
    "\t#load raw data from csv\n",
    "\tload_file = os.path.join(directory, file)\n",
    "\ttemp = np.genfromtxt(load_file, delimiter=',',skip_header=1)\n",
    "\tt = temp[:,0]\n",
    "\tft_triggers = temp[:,1]\n",
    "\tpd1 = temp[:,2]\n",
    "\tpd2 = temp[:,3]\n",
    "\tprint('done')\n",
    "\n",
    "\t#save as h5py file\n",
    "\tprint('saving photodiode data as h5py file...',end='')\n",
    "\tsave_file = os.path.join(directory, 'photodiode.h5')\n",
    "\twith h5py.File(save_file, 'w') as hf:\n",
    "\t\thf.create_dataset('time',  data=t)\n",
    "\t\thf.create_dataset('ft_triggers',  data=ft_triggers)\n",
    "\t\thf.create_dataset('pd1',  data=pd1)\n",
    "\t\thf.create_dataset('pd2',  data=pd2)\n",
    "\tprint('done')\n",
    "\t\n",
    "def load_h5py_pd_data(directory):\n",
    "\t\"\"\" Loads photodiode data from h5py file.\n",
    "\tParameters\n",
    "\t----------\n",
    "\tdirectory: full path to vision folder\n",
    "\tReturns\n",
    "\t-------\n",
    "\tt: 1D numpy array, times of photodiode measurement (in ms)\n",
    "\tpd1: 1D numpy array, photodiode 1 measurements\n",
    "\tpd2: 1D numpy array, photodiode 1 measurements \"\"\"\n",
    "\n",
    "\tprint('loading photodiode data... ',end='')\n",
    "\t#load from h5py file\n",
    "\tload_file = os.path.join(directory, 'photodiode.h5')\n",
    "\twith h5py.File(load_file, 'r') as hf:\n",
    "\t\tt = hf['time'][:]\n",
    "\t\tft_triggers = hf['ft_triggers'][:]\n",
    "\t\tpd1 = hf['pd1'][:]\n",
    "\t\tpd2 = hf['pd2'][:]\n",
    "\tprint('done')\n",
    "\treturn t, ft_triggers, pd1, pd2\n",
    "\n",
    "def load_photodiode(vision_path):\n",
    "\t\"\"\" Tries to load photodiode data from h5py file, and if it doesn't exist loads from csv file.\n",
    "\tParameters\n",
    "\t----------\n",
    "\tvision_path: full path to vision folder\n",
    "\tReturns\n",
    "\t-------\n",
    "\tt: 1D numpy array, times of photodiode measurement (in ms)\n",
    "\tpd1: 1D numpy array, photodiode 1 measurements\n",
    "\tpd2: 1D numpy array, photodiode 1 measurements \"\"\"\n",
    "\n",
    "\t# Try to load from h5py file\n",
    "\ttry:\n",
    "\t\tt, ft_triggers, pd1, pd2 = load_h5py_pd_data(vision_path)\n",
    "\t\t\n",
    "\t# First convert from csv to h5py, then load h5py\n",
    "\texcept:\n",
    "\t\tpd_csv_to_h5py(vision_path,'photodiode.csv')\n",
    "\t\tt, ft_triggers, pd1, pd2 = load_h5py_pd_data(vision_path)\n",
    "\treturn t, ft_triggers, pd1, pd2\n",
    "\n",
    "def get_stimulus_metadata(vision_path, printlog):\n",
    "\t\n",
    "\t### try to get from pickle ###\n",
    "\tpickle_path = os.path.join(vision_path, 'stimulus_metadata.pkl')\n",
    "\tif os.path.exists(pickle_path):\n",
    "\t\tprintlog(\"Loaded from Pickle.\")\n",
    "\t\twith open(pickle_path, 'rb') as f:\n",
    "\t\t\tmetadata = pickle.load(f)\n",
    "\t\treturn metadata['stim_ids'], metadata['angles']\n",
    "\t\n",
    "\t### if no pickle, load from .h5 and save pickle for future ###\n",
    "\tprintlog(\"No pickle; parsing visprotocol .h5\")\n",
    "\tfname = [x for x in os.listdir(vision_path) if '.hdf5' in x][0]\n",
    "\tvisprotocol_file = os.path.join(vision_path, fname)\n",
    "\n",
    "\tstim_ids = []\n",
    "\tangles = []\n",
    "\twith h5py.File(visprotocol_file, 'r') as f:\n",
    "\n",
    "\t\t### loop over flies and series to find the one that has many stim presentations (others were aborted)\n",
    "\t\t# note it is critical each fly has their own .h5 file saved\n",
    "\t\tfly_ids = list(f['Flies'].keys())\n",
    "\t\tprintlog(\"Found fly ids: {}\".format(fly_ids))\n",
    "\t\tfor fly_id in fly_ids:\n",
    "\t\t\t\n",
    "\t\t\tseries = list(f['Flies'][fly_id]['epoch_runs'].keys())\n",
    "\t\t\tprintlog(\"Found series: {}\".format(series))\n",
    "\t\t\tfor serie in series:\n",
    "\n",
    "\t\t\t\tepoch_ids = f['Flies'][fly_id]['epoch_runs'][serie].get('epochs').keys()\n",
    "\t\t\t\tprintlog(str(len(epoch_ids)))\n",
    "\t\t\t\tfor i, epoch_id in enumerate(epoch_ids):\n",
    "\t\t\t\t\tstim_id = f['Flies'][fly_id]['epoch_runs'][serie].get('epochs').get(epoch_id).attrs['component_stim_type']\n",
    "\t\t\t\t\tstim_ids.append(stim_id)\n",
    "\t\t\t\t\tif stim_id == 'DriftingSquareGrating':\n",
    "\t\t\t\t\t\tangle = f['Flies'][fly_id]['epoch_runs'][serie].get('epochs').get(epoch_id).attrs['angle']\n",
    "\t\t\t\t\t\tangles.append(angle)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tangles.append(None)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\tif len(stim_ids) > 100:\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t### save pickle for next time\n",
    "\t\t\t\t\tmetadata = {'stim_ids': stim_ids, 'angles': angles}\n",
    "\t\t\t\t\tsave_file = os.path.join(vision_path, 'stimulus_metadata.pkl')\n",
    "\t\t\t\t\twith open(save_file, 'wb') as f:\n",
    "\t\t\t\t\t\tpickle.dump(metadata, f)\n",
    "\t\t\t\t\tprintlog(\"created {}\".format(save_file))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\treturn stim_ids, angles\n",
    "\t\tprintlog('Could not get visual metadata.')\n",
    "\t\n",
    "\n",
    "def extract_stim_times_from_pd(photodiode_trace, time_vector):\n",
    "\tthreshold=0.8,\n",
    "\tcommand_frame_rate=120\n",
    "\tsample_rate = 10000\n",
    "\tminimum_epoch_separation = 0.9 * (3 + 0) * sample_rate\n",
    "\n",
    "\t# shift & normalize so frame monitor trace lives on [0 1]\n",
    "\tphotodiode_trace = photodiode_trace - np.min(photodiode_trace)\n",
    "\tphotodiode_trace = photodiode_trace / np.max(photodiode_trace)\n",
    "\n",
    "\t# find frame flip times\n",
    "\tV_orig = photodiode_trace[0:-2]\n",
    "\tV_shift = photodiode_trace[1:-1]\n",
    "\tups = np.where(np.logical_and(V_orig < threshold, V_shift >= threshold))[0] + 1\n",
    "\tdowns = np.where(np.logical_and(V_orig >= threshold, V_shift < threshold))[0] + 1\n",
    "\tframe_times = np.sort(np.append(ups, downs))\n",
    "\n",
    "\t# Use frame flip times to find stimulus start times\n",
    "\tstimulus_start_frames = np.append(0, np.where(np.diff(frame_times) > minimum_epoch_separation)[0] + 1)\n",
    "\tstimulus_end_frames = np.append(np.where(np.diff(frame_times) > minimum_epoch_separation)[0], len(frame_times)-1)\n",
    "\tstimulus_start_times = frame_times[stimulus_start_frames] / sample_rate  # datapoints -> sec\n",
    "\tstimulus_end_times = frame_times[stimulus_end_frames] / sample_rate  # datapoints -> sec\n",
    "\n",
    "\tstim_durations = stimulus_end_times - stimulus_start_times # sec\n",
    "\treturn stimulus_start_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stimulus_metadata(vision_path):\n",
    "\n",
    "    ### try to get from pickle ###\n",
    "    pickle_path = os.path.join(vision_path, 'stimulus_metadata.pkl')\n",
    "    if os.path.exists(pickle_path):\n",
    "        print(\"Loaded from Pickle.\")\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        return metadata['stim_ids'], metadata['angles']\n",
    "\n",
    "    ### if no pickle, load from .h5 and save pickle for future ###\n",
    "    print(\"No pickle; parsing visprotocol .h5\")\n",
    "    fname = [x for x in os.listdir(vision_path) if '.hdf5' in x][0]\n",
    "    visprotocol_file = os.path.join(vision_path, fname)\n",
    "\n",
    "    stim_ids = []\n",
    "    angles = []\n",
    "    with h5py.File(visprotocol_file, 'r') as f:\n",
    "\n",
    "        ### loop over flies and series to find the one that has many stim presentations (others were aborted)\n",
    "        # note it is critical each fly has their own .h5 file saved\n",
    "        fly_ids = list(f['Flies'].keys())\n",
    "        print(\"Found fly ids: {}\".format(fly_ids))\n",
    "        for fly_id in fly_ids:\n",
    "\n",
    "            series = list(f['Flies'][fly_id]['epoch_runs'].keys())\n",
    "            print(\"Found series: {}\".format(series))\n",
    "            for serie in series:\n",
    "\n",
    "                epoch_ids = f['Flies'][fly_id]['epoch_runs'][serie].get('epochs').keys()\n",
    "                print(str(len(epoch_ids)))\n",
    "                for i, epoch_id in enumerate(epoch_ids):\n",
    "                    stim_id = f['Flies'][fly_id]['epoch_runs'][serie].get('epochs').get(epoch_id).attrs['component_stim_type']\n",
    "                    stim_ids.append(stim_id)\n",
    "                    if stim_id == 'DriftingSquareGrating':\n",
    "                        angle = f['Flies'][fly_id]['epoch_runs'][serie].get('epochs').get(epoch_id).attrs['angle']\n",
    "                        angles.append(angle)\n",
    "                    else:\n",
    "                        angles.append(None)\n",
    "\n",
    "                if len(stim_ids) > 100:\n",
    "\n",
    "                    ### save pickle for next time\n",
    "                    metadata = {'stim_ids': stim_ids, 'angles': angles}\n",
    "                    save_file = os.path.join(vision_path, 'stimulus_metadata.pkl')\n",
    "                    with open(save_file, 'wb') as f:\n",
    "                        pickle.dump(metadata, f)\n",
    "                    print(\"created {}\".format(save_file))\n",
    "\n",
    "                    return stim_ids, angles\n",
    "        print('Could not get visual metadata.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func_path = '/oak/stanford/groups/trc/data/Brezovec/2P_Imaging/20190101_walking_dataset/fly_116/func_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading photodiode data... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-1994e37493b6>\", line 12, in <module>\n",
      "    stim_ids, angles = get_stimulus_metadata(vision_path)\n",
      "TypeError: get_stimulus_metadata() missing 1 required positional argument: 'printlog'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1806, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/share/software/user/open/py-jupyter/1.0.0_py36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/share/software/user/open/python/3.6.1/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/share/software/user/open/python/3.6.1/lib/python3.6/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/share/software/user/open/python/3.6.1/lib/python3.6/inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/share/software/user/open/python/3.6.1/lib/python3.6/inspect.py\", line 695, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/share/software/user/open/python/3.6.1/lib/python3.6/inspect.py\", line 679, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/share/software/user/open/python/3.6.1/lib/python3.6/posixpath.py\", line 374, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_stimulus_metadata() missing 1 required positional argument: 'printlog'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "### PREP VISUAL STIMULI ###\n",
    "###########################\n",
    "\n",
    "vision_path = os.path.join(func_path, 'visual')\n",
    "\n",
    "### Load Photodiode ###\n",
    "t, ft_triggers, pd1, pd2 = load_photodiode(vision_path)\n",
    "stimulus_start_times = extract_stim_times_from_pd(pd2, t)\n",
    "\n",
    "### Get Metadata ###\n",
    "stim_ids, angles = get_stimulus_metadata(vision_path)\n",
    "print(F\"Found {len(stim_ids)} presented stimuli.\")\n",
    "\n",
    "# *100 puts in units of 10ms, which will match fictrac\n",
    "starts_angle_0 = [int(stimulus_start_times[i]*100) for i in range(len(stimulus_start_times)) if angles[i] == 0]\n",
    "starts_angle_180 = [int(stimulus_start_times[i]*100) for i in range(len(stimulus_start_times)) if angles[i] == 180]\n",
    "print(F\"starts_angle_0: {len(starts_angle_0)}. starts_angle_180: {len(starts_angle_180)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.asarray(starts_angle_0)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_in_ms = [i*10 for i in starts_angle_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starts_angle_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brain_path = os.path.join(func_path, 'functional_channel_2_moco_zscore_highpass.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamps = brainsss.load_timestamps(os.path.join(func_path, 'imaging'), file='functional.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=-1\n",
    "timestamps[-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load slice 20\n",
    "# interpolate\n",
    "# make interp object\n",
    "interp1d\n",
    "# set stim times to closest datapoint\n",
    "# loop over all presentations and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.arange(0, 9, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
